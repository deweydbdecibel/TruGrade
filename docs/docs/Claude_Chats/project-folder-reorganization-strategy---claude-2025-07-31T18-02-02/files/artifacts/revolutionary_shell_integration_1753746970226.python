#!/usr/bin/env python3
"""
Revolutionary Shell Integration Module
=====================================
Professional-grade integration system for coordinating dataset creation and
revolutionary precision training through a unified command center interface.

Architecture Components:
- Service Discovery & Health Monitoring
- Dataset Pipeline Orchestration  
- Revolutionary Training Coordination
- Professional Error Handling & Recovery
- Real-time Progress Monitoring
- Enterprise-grade Status Management

This module transforms the revolutionary shell into the central command center
for the entire ML training ecosystem.
"""

import asyncio
import json
import logging
import threading
import time
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any, Callable
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import customtkinter as ctk
from tkinter import messagebox, ttk
import tkinter as tk

# Configure professional logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class ServiceStatus(Enum):
    """Professional service status enumeration"""
    ONLINE = "online"
    OFFLINE = "offline"
    DEGRADED = "degraded"
    STARTING = "starting"
    ERROR = "error"
    UNKNOWN = "unknown"

class TrainingState(Enum):
    """Revolutionary training state management"""
    IDLE = "idle"
    DATASET_CREATION = "dataset_creation"
    DATASET_READY = "dataset_ready"
    TRAINING_INITIALIZED = "training_initialized"
    TRAINING_ACTIVE = "training_active"
    TRAINING_COMPLETED = "training_completed"
    ERROR_STATE = "error_state"

@dataclass
class ServiceConfiguration:
    """Professional service configuration container"""
    name: str
    port: int
    script: str
    description: str
    priority: str = "standard"
    health_endpoint: str = "/health"
    api_base: str = "/api"
    timeout: int = 10
    retry_attempts: int = 3

@dataclass
class DatasetMetadata:
    """Advanced dataset metadata management"""
    dataset_id: str
    name: str
    model_type: str
    total_images: int
    annotation_coverage: float
    quality_score: float
    created_at: datetime
    dataset_path: Path
    annotation_path: Optional[Path] = None
    ready_for_training: bool = False

@dataclass
class TrainingSession:
    """Revolutionary training session management"""
    session_id: str
    dataset_metadata: DatasetMetadata
    target_accuracy: float
    configuration: Dict[str, Any]
    status: TrainingState
    progress: float = 0.0
    metrics: Dict[str, float] = None
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    error_message: Optional[str] = None

class ProfessionalHTTPClient:
    """Enterprise-grade HTTP client with advanced retry and error handling"""
    
    def __init__(self, timeout: int = 10, max_retries: int = 3):
        self.session = requests.Session()
        self.timeout = timeout
        
        # Configure professional retry strategy
        retry_strategy = Retry(
            total=max_retries,
            status_forcelist=[429, 500, 502, 503, 504],
            method_whitelist=["HEAD", "GET", "OPTIONS", "POST"],
            backoff_factor=1
        )
        
        adapter = HTTPAdapter(max_retries=retry_strategy)
        self.session.mount("http://", adapter)
        self.session.mount("https://", adapter)
        
        # Professional headers
        self.session.headers.update({
            'Content-Type': 'application/json',
            'User-Agent': 'RevolutionaryShell/1.0 Professional',
            'Accept': 'application/json'
        })
    
    async def async_request(
        self, 
        method: str, 
        url: str, 
        **kwargs
    ) -> requests.Response:
        """Asynchronous HTTP request wrapper"""
        try:
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                lambda: self.session.request(method, url, timeout=self.timeout, **kwargs)
            )
            return response
        except Exception as e:
            logger.error(f"HTTP request failed: {method} {url} - {e}")
            raise
    
    def close(self):
        """Professional resource cleanup"""
        self.session.close()

class ServiceDiscoveryManager:
    """Advanced service discovery and health monitoring system"""
    
    def __init__(self, config_path: Path):
        self.config_path = config_path
        self.services: Dict[str, ServiceConfiguration] = {}
        self.service_status: Dict[str, ServiceStatus] = {}
        self.last_health_check: Dict[str, datetime] = {}
        self.http_client = ProfessionalHTTPClient()
        self.health_check_interval = 30  # seconds
        self.monitoring_active = False
        self.monitoring_thread: Optional[threading.Thread] = None
        
        self._load_service_configuration()
    
    def _load_service_configuration(self) -> None:
        """Load and parse professional service configuration"""
        try:
            with open(self.config_path, 'r') as f:
                config_data = json.load(f)
            
            services_config = config_data.get('services', {})
            
            for service_name, service_data in services_config.items():
                self.services[service_name] = ServiceConfiguration(
                    name=service_name,
                    port=service_data.get('port'),
                    script=service_data.get('script'),
                    description=service_data.get('description', ''),
                    priority=service_data.get('priority', 'standard')
                )
                
                # Initialize status
                self.service_status[service_name] = ServiceStatus.UNKNOWN
                
            logger.info(f"‚úÖ Loaded configuration for {len(self.services)} services")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load service configuration: {e}")
            raise
    
    async def check_service_health(self, service_name: str) -> ServiceStatus:
        """Professional service health verification"""
        if service_name not in self.services:
            return ServiceStatus.UNKNOWN
        
        service = self.services[service_name]
        health_url = f"http://localhost:{service.port}{service.health_endpoint}"
        
        try:
            response = await self.http_client.async_request('GET', health_url)
            
            if response.status_code == 200:
                self.service_status[service_name] = ServiceStatus.ONLINE
                self.last_health_check[service_name] = datetime.now()
                return ServiceStatus.ONLINE
            else:
                self.service_status[service_name] = ServiceStatus.DEGRADED
                return ServiceStatus.DEGRADED
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Health check failed for {service_name}: {e}")
            self.service_status[service_name] = ServiceStatus.OFFLINE
            return ServiceStatus.OFFLINE
    
    async def discover_available_services(self) -> Dict[str, ServiceStatus]:
        """Comprehensive service discovery sweep"""
        discovery_tasks = [
            self.check_service_health(service_name) 
            for service_name in self.services.keys()
        ]
        
        results = await asyncio.gather(*discovery_tasks, return_exceptions=True)
        
        discovered_services = {}
        for service_name, result in zip(self.services.keys(), results):
            if isinstance(result, Exception):
                discovered_services[service_name] = ServiceStatus.ERROR
            else:
                discovered_services[service_name] = result
        
        logger.info(f"üîç Service discovery completed: {len(discovered_services)} services checked")
        return discovered_services
    
    def start_continuous_monitoring(self) -> None:
        """Initiate professional continuous service monitoring"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            daemon=True,
            name="ServiceMonitoring"
        )
        self.monitoring_thread.start()
        logger.info("üîÑ Continuous service monitoring initiated")
    
    def stop_monitoring(self) -> None:
        """Graceful monitoring termination"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        logger.info("‚èπÔ∏è Service monitoring terminated")
    
    def _monitoring_loop(self) -> None:
        """Professional monitoring loop implementation"""
        while self.monitoring_active:
            try:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                loop.run_until_complete(self.discover_available_services())
                loop.close()
                
                time.sleep(self.health_check_interval)
                
            except Exception as e:
                logger.error(f"‚ùå Monitoring loop error: {e}")
                time.sleep(5)  # Brief pause before retry
    
    def get_service_url(self, service_name: str, endpoint: str = "") -> str:
        """Generate professional service URL"""
        if service_name not in self.services:
            raise ValueError(f"Unknown service: {service_name}")
        
        service = self.services[service_name]
        base_url = f"http://localhost:{service.port}"
        
        if endpoint:
            if not endpoint.startswith('/'):
                endpoint = '/' + endpoint
            return f"{base_url}{endpoint}"
        
        return base_url
    
    def __del__(self):
        """Professional cleanup"""
        self.stop_monitoring()
        self.http_client.close()

class DatasetPipelineOrchestrator:
    """Advanced dataset creation and management orchestrator"""
    
    def __init__(self, service_manager: ServiceDiscoveryManager):
        self.service_manager = service_manager
        self.current_datasets: Dict[str, DatasetMetadata] = {}
        self.active_sessions: Dict[str, Any] = {}
    
    async def create_dataset(
        self,
        name: str,
        model_type: str,
        description: str = ""
    ) -> Tuple[bool, Dict[str, Any]]:
        """Professional dataset creation coordination"""
        
        try:
            # Verify ML Training Studio availability
            studio_status = await self.service_manager.check_service_health('ml_training_studio')
            if studio_status != ServiceStatus.ONLINE:
                return False, {
                    "error": "ML Training Studio unavailable",
                    "status": studio_status.value
                }
            
            # Initiate dataset creation
            studio_url = self.service_manager.get_service_url(
                'ml_training_studio', 
                '/api/datasets/create'
            )
            
            payload = {
                'name': name,
                'model_type': model_type,
                'annotation_format': 'coco_json',
                'description': description
            }
            
            response = await self.service_manager.http_client.async_request(
                'POST', studio_url, json=payload
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    dataset_id = result.get('dataset_id')
                    
                    # Create metadata tracking
                    metadata = DatasetMetadata(
                        dataset_id=dataset_id,
                        name=name,
                        model_type=model_type,
                        total_images=0,
                        annotation_coverage=0.0,
                        quality_score=0.0,
                        created_at=datetime.now(),
                        dataset_path=Path(result.get('dataset_path', ''))
                    )
                    
                    self.current_datasets[dataset_id] = metadata
                    
                    return True, {
                        "dataset_id": dataset_id,
                        "management_url": result.get('management_url'),
                        "metadata": asdict(metadata)
                    }
            
            return False, {
                "error": "Dataset creation failed",
                "response": response.text
            }
            
        except Exception as e:
            logger.error(f"‚ùå Dataset creation error: {e}")
            return False, {"error": str(e)}
    
    async def get_dataset_status(self, dataset_id: str) -> Optional[DatasetMetadata]:
        """Retrieve comprehensive dataset status"""
        
        if dataset_id not in self.current_datasets:
            return None
        
        try:
            # Query current dataset status
            studio_url = self.service_manager.get_service_url(
                'ml_training_studio',
                f'/api/datasets/{dataset_id}/status'
            )
            
            response = await self.service_manager.http_client.async_request(
                'GET', studio_url
            )
            
            if response.status_code == 200:
                status_data = response.json()
                
                # Update metadata
                metadata = self.current_datasets[dataset_id]
                if 'statistics' in status_data:
                    stats = status_data['statistics']
                    metadata.total_images = stats.get('total_images', 0)
                    metadata.annotation_coverage = stats.get('annotation_coverage', 0.0)
                    metadata.quality_score = stats.get('dataset_quality', 0.0)
                    metadata.ready_for_training = status_data.get('ready_for_training', False)
                
                return metadata
            
        except Exception as e:
            logger.error(f"‚ùå Dataset status retrieval error: {e}")
        
        return self.current_datasets.get(dataset_id)
    
    async def list_available_datasets(self) -> List[DatasetMetadata]:
        """Enumerate all available datasets"""
        
        try:
            studio_url = self.service_manager.get_service_url(
                'ml_training_studio',
                '/api/datasets'
            )
            
            response = await self.service_manager.http_client.async_request(
                'GET', studio_url
            )
            
            if response.status_code == 200:
                result = response.json()
                datasets = result.get('datasets', [])
                
                # Update internal tracking
                for dataset_data in datasets:
                    dataset_id = dataset_data.get('id')
                    if dataset_id:
                        metadata = DatasetMetadata(
                            dataset_id=dataset_id,
                            name=dataset_data.get('name', 'Unknown'),
                            model_type=dataset_data.get('model_type', 'Unknown'),
                            total_images=dataset_data.get('statistics', {}).get('total_images', 0),
                            annotation_coverage=dataset_data.get('statistics', {}).get('annotation_coverage', 0.0),
                            quality_score=dataset_data.get('statistics', {}).get('dataset_quality', 0.0),
                            created_at=datetime.fromisoformat(dataset_data.get('created_at', datetime.now().isoformat())),
                            dataset_path=Path(dataset_data.get('path', '')),
                            ready_for_training=dataset_data.get('ready_for_training', False)
                        )
                        self.current_datasets[dataset_id] = metadata
                
                return list(self.current_datasets.values())
            
        except Exception as e:
            logger.error(f"‚ùå Dataset enumeration error: {e}")
        
        return []

class RevolutionaryTrainingCoordinator:
    """Advanced revolutionary training orchestration and coordination"""
    
    def __init__(self, service_manager: ServiceDiscoveryManager):
        self.service_manager = service_manager
        self.active_training_sessions: Dict[str, TrainingSession] = {}
        self.training_history: List[TrainingSession] = []
    
    async def initialize_revolutionary_training(
        self,
        target_accuracy: float = 0.999,
        enable_photometric: bool = True,
        enable_24_point: bool = True
    ) -> Tuple[bool, Dict[str, Any]]:
        """Initialize the revolutionary precision orchestrator"""
        
        try:
            # Verify service availability
            orchestrator_status = await self.service_manager.check_service_health(
                'revolutionary_precision_orchestrator'
            )
            
            if orchestrator_status != ServiceStatus.ONLINE:
                return False, {
                    "error": "Revolutionary Precision Orchestrator unavailable",
                    "status": orchestrator_status.value
                }
            
            # Initialize revolutionary training system
            init_url = self.service_manager.get_service_url(
                'revolutionary_precision_orchestrator',
                '/api/revolutionary-training/initialize'
            )
            
            payload = {
                'target_accuracy': target_accuracy,
                'enable_photometric': enable_photometric,
                'enable_24_point': enable_24_point
            }
            
            response = await self.service_manager.http_client.async_request(
                'POST', init_url, json=payload
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    return True, result.get('configuration', {})
            
            return False, {
                "error": "Revolutionary training initialization failed",
                "response": response.text
            }
            
        except Exception as e:
            logger.error(f"‚ùå Revolutionary training initialization error: {e}")
            return False, {"error": str(e)}
    
    async def execute_revolutionary_training(
        self,
        dataset_metadata: DatasetMetadata,
        training_configuration: Dict[str, Any] = None
    ) -> Tuple[bool, str]:
        """Execute revolutionary precision training"""
        
        try:
            # Generate unique session ID
            session_id = f"training_{int(time.time())}"
            
            # Create training session
            training_session = TrainingSession(
                session_id=session_id,
                dataset_metadata=dataset_metadata,
                target_accuracy=training_configuration.get('target_accuracy', 0.999),
                configuration=training_configuration or {},
                status=TrainingState.TRAINING_INITIALIZED,
                started_at=datetime.now()
            )
            
            self.active_training_sessions[session_id] = training_session
            
            # Execute training
            training_url = self.service_manager.get_service_url(
                'revolutionary_precision_orchestrator',
                '/api/revolutionary-training/execute'
            )
            
            payload = {
                'dataset_path': str(dataset_metadata.dataset_path),
                'annotation_path': str(dataset_metadata.annotation_path) if dataset_metadata.annotation_path else None
            }
            
            # Update status
            training_session.status = TrainingState.TRAINING_ACTIVE
            
            response = await self.service_manager.http_client.async_request(
                'POST', training_url, json=payload
            )
            
            if response.status_code == 200:
                result = response.json()
                if result.get('success'):
                    training_session.status = TrainingState.TRAINING_COMPLETED
                    training_session.completed_at = datetime.now()
                    training_session.metrics = result.get('training_report', {})
                    
                    # Move to history
                    self.training_history.append(training_session)
                    del self.active_training_sessions[session_id]
                    
                    return True, session_id
            
            # Handle failure
            training_session.status = TrainingState.ERROR_STATE
            training_session.error_message = result.get('error', 'Unknown training error')
            
            return False, session_id
            
        except Exception as e:
            logger.error(f"‚ùå Revolutionary training execution error: {e}")
            if session_id in self.active_training_sessions:
                self.active_training_sessions[session_id].status = TrainingState.ERROR_STATE
                self.active_training_sessions[session_id].error_message = str(e)
            return False, session_id
    
    async def get_training_status(self, session_id: str) -> Optional[TrainingSession]:
        """Retrieve comprehensive training session status"""
        
        # Check active sessions
        if session_id in self.active_training_sessions:
            session = self.active_training_sessions[session_id]
            
            # Query real-time status
            try:
                status_url = self.service_manager.get_service_url(
                    'revolutionary_precision_orchestrator',
                    '/api/revolutionary-training/status'
                )
                
                response = await self.service_manager.http_client.async_request(
                    'GET', status_url
                )
                
                if response.status_code == 200:
                    status_data = response.json()
                    if status_data.get('success'):
                        status_info = status_data.get('status', {})
                        session.progress = min(
                            status_info.get('current_epoch', 0) / 100.0, 1.0
                        )
                        
                        # Update metrics if available
                        if 'best_accuracy' in status_info:
                            session.metrics = session.metrics or {}
                            session.metrics['current_accuracy'] = status_info['best_accuracy']
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Status query failed for session {session_id}: {e}")
            
            return session
        
        # Check historical sessions
        for historical_session in self.training_history:
            if historical_session.session_id == session_id:
                return historical_session
        
        return None

class RevolutionaryShellIntegration:
    """
    Professional integration controller for Revolutionary Shell command center.
    
    This class orchestrates the complete workflow from dataset creation through
    revolutionary training execution, providing a unified interface for the
    entire machine learning pipeline.
    """
    
    def __init__(self, config_path: Path):
        self.config_path = config_path
        
        # Initialize professional subsystems
        self.service_manager = ServiceDiscoveryManager(config_path)
        self.dataset_orchestrator = DatasetPipelineOrchestrator(self.service_manager)
        self.training_coordinator = RevolutionaryTrainingCoordinator(self.service_manager)
        
        # State management
        self.current_workflow_state = TrainingState.IDLE
        self.active_dataset: Optional[DatasetMetadata] = None
        self.active_training_session: Optional[str] = None
        
        # UI Integration callbacks
        self.status_update_callbacks: List[Callable] = []
        self.progress_update_callbacks: List[Callable] = []
        
        logger.info("üöÄ Revolutionary Shell Integration initialized")
    
    def register_status_callback(self, callback: Callable) -> None:
        """Register UI status update callback"""
        self.status_update_callbacks.append(callback)
    
    def register_progress_callback(self, callback: Callable) -> None:
        """Register training progress callback"""
        self.progress_update_callbacks.append(callback)
    
    def _notify_status_update(self, status_data: Dict[str, Any]) -> None:
        """Notify registered callbacks of status changes"""
        for callback in self.status_update_callbacks:
            try:
                callback(status_data)
            except Exception as e:
                logger.error(f"‚ùå Status callback error: {e}")
    
    def _notify_progress_update(self, progress_data: Dict[str, Any]) -> None:
        """Notify registered callbacks of progress updates"""
        for callback in self.progress_update_callbacks:
            try:
                callback(progress_data)
            except Exception as e:
                logger.error(f"‚ùå Progress callback error: {e}")
    
    async def initialize_system(self) -> Tuple[bool, Dict[str, Any]]:
        """Comprehensive system initialization and service discovery"""
        
        try:
            # Start service monitoring
            self.service_manager.start_continuous_monitoring()
            
            # Discover available services
            service_status = await self.service_manager.discover_available_services()
            
            # Check critical services
            critical_services = ['ml_training_studio', 'revolutionary_precision_orchestrator']
            system_operational = all(
                service_status.get(service) == ServiceStatus.ONLINE 
                for service in critical_services
            )
            
            # Initialize revolutionary training system
            training_init_success = False
            training_config = {}
            
            if service_status.get('revolutionary_precision_orchestrator') == ServiceStatus.ONLINE:
                training_init_success, training_config = await self.training_coordinator.initialize_revolutionary_training()
            
            initialization_report = {
                "system_operational": system_operational,
                "service_status": {name: status.value for name, status in service_status.items()},
                "revolutionary_training_ready": training_init_success,
                "training_configuration": training_config,
                "critical_services_online": len([
                    s for s in critical_services 
                    if service_status.get(s) == ServiceStatus.ONLINE
                ]),
                "total_services": len(service_status)
            }
            
            self._notify_status_update(initialization_report)
            
            return system_operational, initialization_report
            
        except Exception as e:
            logger.error(f"‚ùå System initialization failed: {e}")
            return False, {"error": str(e)}
    
    async def create_new_dataset(
        self,
        name: str,
        model_type: str,
        description: str = ""
    ) -> Tuple[bool, Dict[str, Any]]:
        """Orchestrate new dataset creation workflow"""
        
        try:
            self.current_workflow_state = TrainingState.DATASET_CREATION
            self._notify_status_update({"workflow_state": self.current_workflow_state.value})
            
            success, result = await self.dataset_orchestrator.create_dataset(
                name, model_type, description
            )
            
            if success:
                dataset_id = result.get('dataset_id')
                self.active_dataset = self.dataset_orchestrator.current_datasets.get(dataset_id)
                self.current_workflow_state = TrainingState.DATASET_READY
                
                self._notify_status_update({
                    "workflow_state": self.current_workflow_state.value,
                    "active_dataset": asdict(self.active_dataset) if self.active_dataset else None
                })
            else:
                self.current_workflow_state = TrainingState.ERROR_STATE
                self._notify_status_update({
                    "workflow_state": self.current_workflow_state.value,
                    "error": result.get('error')
                })
            
            return success, result
            
        except Exception as e:
            logger.error(f"‚ùå Dataset creation workflow error: {e}")
            self.current_workflow_state = TrainingState.ERROR_STATE
            return False, {"error": str(e)}
    
    async def execute_revolutionary_training_workflow(
        self,
        dataset_id: Optional[str] = None,
        training_configuration: Dict[str, Any] = None
    ) -> Tuple[bool, str]:
        """Execute complete revolutionary training workflow"""
        
        try:
            # Determine dataset
            if dataset_id:
                dataset_metadata = await self.dataset_orchestrator.get_dataset_status(dataset_id)
                if not dataset_metadata:
                    return False, "Dataset not found"
                self.active_dataset = dataset_metadata
            elif not self.active_dataset:
                return False, "No active dataset selected"
            
            # Verify dataset readiness
            if not self.active_dataset.ready_for_training:
                return False, "Dataset not ready for training"
            
            self.current_workflow_state = TrainingState.TRAINING_INITIALIZED
            self._notify_status_update({
                "workflow_state": self.current_workflow_state.value,
                "active_dataset": asdict(self.active_dataset)
            })
            
            # Execute revolutionary training
            success, session_id = await self.training_coordinator.execute_revolutionary_training(
                self.active_dataset, training_configuration
            )
            
            if success:
                self.active_training_session = session_id
                self.current_workflow_state = TrainingState.TRAINING_ACTIVE
                
                # Start progress monitoring
                asyncio.create_task(self._monitor_training_progress(session_id))
            else:
                self.current_workflow_state = TrainingState.ERROR_STATE
            
            self._notify_status_update({
                "workflow_state": self.current_workflow_state.value,
                "training_session_id": session_id
            })
            
            return success, session_id
            
        except Exception as e:
            logger.error(f"‚ùå Revolutionary training workflow error: {e}")
            self.current_workflow_state = TrainingState.ERROR_STATE
            return False, str(e)
    
    async def _monitor_training_progress(self, session_id: str) -> None:
        """Professional training progress monitoring"""
        
        while self.current_workflow_state == TrainingState.TRAINING_ACTIVE:
            try:
                session = await self.training_coordinator.get_training_status(session_id)
                
                if session:
                    progress_data = {
                        "session_id": session_id,
                        "progress": session.progress,
                        "status": session.status.value,
                        "metrics": session.metrics,
                        "error": session.error_message
                    }
                    
                    self._notify_progress_update(progress_data)
                    
                    # Check for completion
                    if session.status in [TrainingState.TRAINING_COMPLETED, TrainingState.ERROR_STATE]:
                        self.current_workflow_state = session.status
                        self._notify_status_update({
                            "workflow_state": self.current_workflow_state.value,
                            "final_session": asdict(session)
                        })
                        break
                
                await asyncio.sleep(5)  # Professional polling interval
                
            except Exception as e:
                logger.error(f"‚ùå Training progress monitoring error: {e}")
                await asyncio.sleep(10)  # Extended interval on error
    
    async def get_system_status(self) -> Dict[str, Any]:
        """Comprehensive system status report"""
        
        try:
            # Service health status
            service_status = await self.service_manager.discover_available_services()
            
            # Dataset status
            available_datasets = await self.dataset_orchestrator.list_available_datasets()
            
            # Training session status
            active_sessions = list(self.training_coordinator.active_training_sessions.values())
            training_history = self.training_coordinator.training_history
            
            status_report = {
                "system_operational": True,
                "workflow_state": self.current_workflow_state.value,
                "services": {name: status.value for name, status in service_status.items()},
                "datasets": {
                    "total": len(available_datasets),
                    "ready_for_training": len([d for d in available_datasets if d.ready_for_training]),
                    "active_dataset": asdict(self.active_dataset) if self.active_dataset else None
                },
                "training": {
                    "active_sessions": len(active_sessions),
                    "total_completed": len(training_history),
                    "current_session": self.active_training_session
                },
                "timestamp": datetime.now().isoformat()
            }
            
            return status_report
            
        except Exception as e:
            logger.error(f"‚ùå System status retrieval error: {e}")
            return {
                "system_operational": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }
    
    def shutdown_system(self) -> None:
        """Professional system shutdown and cleanup"""
        try:
            # Stop monitoring
            self.service_manager.stop_monitoring()
            
            # Cleanup HTTP client
            self.service_manager.http_client.close()
            
            logger.info("‚úÖ Revolutionary Shell Integration shutdown completed")
            
        except Exception as e:
            logger.error(f"‚ùå Shutdown error: {e}")
