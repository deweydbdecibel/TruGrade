#!/usr/bin/env python3
"""
🚀 Revolutionary ML Training Studio - Dataset Organization Engine
===============================================================

Comprehensive dataset management for revolutionary card grading ML:
- Modular training: Edge, Corner, Damage, Surface, Photometric Fusion
- Multi-format support: COCO JSON, YOLO, CSV with intelligent conversion
- Active learning pipeline: Raw → Predictions → Corrections → Retrain
- Professional parameter management for advanced training
- Revolutionary photometric fusion preparation

Built for gods, designed for industry disruption! 🔥
"""

import asyncio
import json
import logging
import shutil
import uuid
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import pandas as pd
import cv2
import numpy as np
from PIL import Image

from fastapi import FastAPI, HTTPException, Form, UploadFile, File, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse, JSONResponse
from sqlalchemy import create_engine, Column, String, Float, DateTime, JSON, Integer, Boolean, Text
from sqlalchemy.orm import declarative_base, sessionmaker
from sqlalchemy.dialects.postgresql import UUID

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Database setup
DATABASE_URL = "postgresql://revolutionary_user:revolutionary_pass@localhost/card_grading"
engine = create_engine(DATABASE_URL)
SessionLocal = sessionmaker(bind=engine)
Base = declarative_base()

class ModelType(Enum):
    """Revolutionary model types for comprehensive training"""
    EDGE_DETECTION = "edge_detection"
    CORNER_DETECTION = "corner_detection"
    EDGE_DAMAGE = "edge_damage"
    CORNER_DAMAGE = "corner_damage"
    SURFACE_DAMAGE = "surface_damage"
    CENTERING_ANALYSIS = "centering_analysis"
    PHOTOMETRIC_FUSION = "photometric_fusion"  # The revolutionary stuff!
    MULTI_MODAL = "multi_modal"

class AnnotationFormat(Enum):
    """Supported annotation formats with intelligent conversion"""
    COCO_JSON = "coco_json"
    YOLO_TXT = "yolo_txt"
    CSV_TABULAR = "csv_tabular"
    CUSTOM_JSON = "custom_json"
    DETECTRON2 = "detectron2"
    MASK_RCNN = "mask_rcnn"

class DatasetStage(Enum):
    """Dataset stages for active learning pipeline"""
    RAW_IMAGES = "raw_images"           # Original uploaded images
    AI_PREDICTIONS = "ai_predictions"   # Model-generated annotations
    CORRECTED_LABELS = "corrected_labels"  # Human-corrected ground truth
    VALIDATED = "validated"             # Quality checked and ready
    TRAINING_READY = "training_ready"   # Processed for model training

class TrainingParameters(Enum):
    """Professional training parameters from Kaggle/Roboflow research"""
    LEARNING_RATE = "learning_rate"
    BATCH_SIZE = "batch_size"
    EPOCHS = "epochs"
    AUGMENTATION = "augmentation"
    LOSS_FUNCTION = "loss_function"
    OPTIMIZER = "optimizer"
    SCHEDULER = "scheduler"
    REGULARIZATION = "regularization"
    ARCHITECTURE = "architecture"
    PRETRAINED_WEIGHTS = "pretrained_weights"

@dataclass
class DatasetConfiguration:
    """Comprehensive dataset configuration"""
    dataset_id: str
    name: str
    model_type: ModelType
    annotation_format: AnnotationFormat
    description: str
    created_at: datetime
    
    # Directory structure
    base_path: Path
    images_path: Path
    annotations_path: Path
    predictions_path: Path
    corrections_path: Path
    
    # Training parameters
    training_params: Dict[str, Any]
    
    # Metadata
    total_images: int = 0
    annotated_images: int = 0
    validated_images: int = 0
    dataset_quality: float = 0.0
    
    # Active learning stats
    predictions_count: int = 0
    corrections_count: int = 0
    retrain_cycles: int = 0

class DatasetConverter:
    """Intelligent dataset format converter"""
    
    def __init__(self):
        self.supported_formats = [fmt for fmt in AnnotationFormat]
        
    def detect_format(self, annotation_path: Path) -> AnnotationFormat:
        """Automatically detect annotation format"""
        if annotation_path.suffix == '.json':
            try:
                with open(annotation_path, 'r') as f:
                    data = json.load(f)
                    
                if 'images' in data and 'annotations' in data and 'categories' in data:
                    return AnnotationFormat.COCO_JSON
                else:
                    return AnnotationFormat.CUSTOM_JSON
            except:
                return AnnotationFormat.CUSTOM_JSON
                
        elif annotation_path.suffix == '.txt':
            return AnnotationFormat.YOLO_TXT
            
        elif annotation_path.suffix == '.csv':
            return AnnotationFormat.CSV_TABULAR
            
        else:
            raise ValueError(f"Unknown annotation format: {annotation_path.suffix}")
    
    def convert_yolo_to_coco(self, yolo_dir: Path, output_path: Path, 
                           images_dir: Path) -> Dict[str, Any]:
        """Convert YOLO format to COCO JSON"""
        coco_data = {
            "images": [],
            "annotations": [],
            "categories": [
                {"id": 0, "name": "card", "supercategory": "object"},
                {"id": 1, "name": "border", "supercategory": "border"},
                {"id": 2, "name": "corner", "supercategory": "corner"},
                {"id": 3, "name": "edge", "supercategory": "edge"},
                {"id": 4, "name": "damage", "supercategory": "damage"}
            ]
        }
        
        annotation_id = 1
        
        for img_file in images_dir.glob("*.jpg"):
            # Add image info
            img = cv2.imread(str(img_file))
            height, width = img.shape[:2]
            
            image_info = {
                "id": len(coco_data["images"]) + 1,
                "file_name": img_file.name,
                "width": width,
                "height": height
            }
            coco_data["images"].append(image_info)
            
            # Convert YOLO annotations
            yolo_file = yolo_dir / f"{img_file.stem}.txt"
            if yolo_file.exists():
                with open(yolo_file, 'r') as f:
                    for line in f:
                        parts = line.strip().split()
                        if len(parts) >= 5:
                            class_id = int(parts[0])
                            cx, cy, w, h = map(float, parts[1:5])
                            
                            # Convert normalized to absolute coordinates
                            abs_cx = cx * width
                            abs_cy = cy * height
                            abs_w = w * width
                            abs_h = h * height
                            
                            # COCO uses top-left corner + width/height
                            x = abs_cx - abs_w / 2
                            y = abs_cy - abs_h / 2
                            
                            annotation = {
                                "id": annotation_id,
                                "image_id": image_info["id"],
                                "category_id": class_id,
                                "bbox": [x, y, abs_w, abs_h],
                                "area": abs_w * abs_h,
                                "iscrowd": 0
                            }
                            coco_data["annotations"].append(annotation)
                            annotation_id += 1
        
        # Save COCO JSON
        with open(output_path, 'w') as f:
            json.dump(coco_data, f, indent=2)
            
        return coco_data
    
    def convert_coco_to_yolo(self, coco_path: Path, output_dir: Path) -> bool:
        """Convert COCO JSON to YOLO format"""
        try:
            with open(coco_path, 'r') as f:
                coco_data = json.load(f)
            
            # Create image_id to filename mapping
            id_to_filename = {img["id"]: img for img in coco_data["images"]}
            
            # Group annotations by image
            annotations_by_image = {}
            for ann in coco_data["annotations"]:
                image_id = ann["image_id"]
                if image_id not in annotations_by_image:
                    annotations_by_image[image_id] = []
                annotations_by_image[image_id].append(ann)
            
            # Convert each image's annotations
            for image_id, annotations in annotations_by_image.items():
                image_info = id_to_filename[image_id]
                yolo_filename = output_dir / f"{Path(image_info['file_name']).stem}.txt"
                
                with open(yolo_filename, 'w') as f:
                    for ann in annotations:
                        bbox = ann["bbox"]
                        x, y, w, h = bbox
                        
                        # Convert to normalized center coordinates
                        cx = (x + w / 2) / image_info["width"]
                        cy = (y + h / 2) / image_info["height"]
                        nw = w / image_info["width"]
                        nh = h / image_info["height"]
                        
                        class_id = ann["category_id"]
                        f.write(f"{class_id} {cx} {cy} {nw} {nh}\n")
            
            return True
            
        except Exception as e:
            logger.error(f"COCO to YOLO conversion failed: {e}")
            return False
    
    def convert_to_csv(self, coco_path: Path, output_path: Path) -> bool:
        """Convert COCO to CSV tabular format"""
        try:
            with open(coco_path, 'r') as f:
                coco_data = json.load(f)
            
            rows = []
            id_to_filename = {img["id"]: img["file_name"] for img in coco_data["images"]}
            id_to_category = {cat["id"]: cat["name"] for cat in coco_data["categories"]}
            
            for ann in coco_data["annotations"]:
                row = {
                    "image_file": id_to_filename[ann["image_id"]],
                    "category": id_to_category[ann["category_id"]],
                    "bbox_x": ann["bbox"][0],
                    "bbox_y": ann["bbox"][1], 
                    "bbox_width": ann["bbox"][2],
                    "bbox_height": ann["bbox"][3],
                    "area": ann["area"]
                }
                rows.append(row)
            
            df = pd.DataFrame(rows)
            df.to_csv(output_path, index=False)
            return True
            
        except Exception as e:
            logger.error(f"COCO to CSV conversion failed: {e}")
            return False

class RevolutionaryDatasetManager:
    """Revolutionary dataset management engine"""
    
    def __init__(self, base_data_path: str = "data/revolutionary_datasets"):
        self.base_path = Path(base_data_path)
        self.base_path.mkdir(parents=True, exist_ok=True)
        
        # Initialize converter
        self.converter = DatasetConverter()
        
        # Create modular structure
        self.module_paths = {
            ModelType.EDGE_DETECTION: self.base_path / "edge_detection",
            ModelType.CORNER_DETECTION: self.base_path / "corner_detection", 
            ModelType.EDGE_DAMAGE: self.base_path / "edge_damage",
            ModelType.CORNER_DAMAGE: self.base_path / "corner_damage",
            ModelType.SURFACE_DAMAGE: self.base_path / "surface_damage",
            ModelType.CENTERING_ANALYSIS: self.base_path / "centering_analysis",
            ModelType.PHOTOMETRIC_FUSION: self.base_path / "photometric_fusion",
            ModelType.MULTI_MODAL: self.base_path / "multi_modal"
        }
        
        # Create all module directories
        for module_path in self.module_paths.values():
            module_path.mkdir(parents=True, exist_ok=True)
        
        # Active datasets
        self.datasets: Dict[str, DatasetConfiguration] = {}
        
        logger.info("🚀 Revolutionary Dataset Manager initialized")
        logger.info(f"📁 Base path: {self.base_path}")
        
    def create_dataset(self, name: str, model_type: ModelType, 
                      annotation_format: AnnotationFormat, 
                      description: str = "",
                      training_params: Dict[str, Any] = None) -> str:
        """Create a new revolutionary dataset"""
        
        dataset_id = str(uuid.uuid4())
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        dataset_name = f"{timestamp}_{name}_{model_type.value}"
        
        # Create dataset directory structure
        module_base = self.module_paths[model_type]
        dataset_dir = module_base / dataset_name
        
        # Active learning pipeline directories
        images_dir = dataset_dir / "images"
        annotations_dir = dataset_dir / "annotations"
        predictions_dir = dataset_dir / "predictions"
        corrections_dir = dataset_dir / "corrections"
        training_dir = dataset_dir / "training_ready"
        
        # Create all directories
        for dir_path in [dataset_dir, images_dir, annotations_dir, 
                        predictions_dir, corrections_dir, training_dir]:
            dir_path.mkdir(parents=True, exist_ok=True)
        
        # Default training parameters
        if training_params is None:
            training_params = self._get_default_training_params(model_type)
        
        # Create dataset configuration
        config = DatasetConfiguration(
            dataset_id=dataset_id,
            name=name,
            model_type=model_type,
            annotation_format=annotation_format,
            description=description,
            created_at=datetime.now(),
            base_path=dataset_dir,
            images_path=images_dir,
            annotations_path=annotations_dir,
            predictions_path=predictions_dir,
            corrections_path=corrections_dir,
            training_params=training_params
        )
        
        # Save configuration
        config_file = dataset_dir / "dataset_config.json"
        with open(config_file, 'w') as f:
            json.dump({
                "dataset_id": dataset_id,
                "name": name,
                "model_type": model_type.value,
                "annotation_format": annotation_format.value,
                "description": description,
                "created_at": datetime.now().isoformat(),
                "training_params": training_params
            }, f, indent=2)
        
        # Store in memory
        self.datasets[dataset_id] = config
        
        logger.info(f"✅ Created revolutionary dataset: {name}")
        logger.info(f"🎯 Model type: {model_type.value}")
        logger.info(f"📁 Path: {dataset_dir}")
        
        return dataset_id
    
    def _get_default_training_params(self, model_type: ModelType) -> Dict[str, Any]:
        """Get optimized default training parameters by model type"""
        
        base_params = {
            "epochs": 200,
            "batch_size": 4,
            "learning_rate": 0.001,
            "optimizer": "AdamW",
            "scheduler": "ReduceLROnPlateau",
            "weight_decay": 0.01
        }
        
        # Model-specific optimizations
        if model_type == ModelType.EDGE_DETECTION:
            base_params.update({
                "architecture": "Detectron2",
                "loss_function": "FocalLoss",
                "augmentation": {
                    "rotation": 5,
                    "brightness": 0.1,
                    "contrast": 0.1,
                    "gaussian_noise": 0.01
                }
            })
        elif model_type == ModelType.CORNER_DETECTION:
            base_params.update({
                "architecture": "Mask_RCNN",
                "loss_function": "SmoothL1Loss",
                "augmentation": {
                    "rotation": 2,
                    "perspective": 0.05,
                    "elastic_transform": 0.1
                }
            })
        elif model_type == ModelType.PHOTOMETRIC_FUSION:
            base_params.update({
                "architecture": "Custom_Fusion",
                "learning_rate": 0.0005,  # Lower for complex models
                "epochs": 300,            # More epochs for fusion
                "loss_function": "MultiModalLoss",
                "fusion_strategy": "early_fusion"
            })
        
        return base_params
    
    def upload_images(self, dataset_id: str, image_files: List[UploadFile]) -> Dict[str, Any]:
        """Upload images to dataset with validation"""
        
        if dataset_id not in self.datasets:
            raise ValueError(f"Dataset {dataset_id} not found")
        
        config = self.datasets[dataset_id]
        uploaded_files = []
        failed_files = []
        
        for image_file in image_files:
            try:
                # Validate image
                if not self._validate_image(image_file):
                    failed_files.append({
                        "filename": image_file.filename,
                        "error": "Invalid image format"
                    })
                    continue
                
                # Save image
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                safe_filename = f"{timestamp}_{image_file.filename}"
                image_path = config.images_path / safe_filename
                
                with open(image_path, 'wb') as f:
                    content = image_file.file.read()
                    f.write(content)
                
                uploaded_files.append({
                    "original_name": image_file.filename,
                    "saved_name": safe_filename,
                    "path": str(image_path),
                    "size": len(content)
                })
                
                logger.info(f"📁 Uploaded: {safe_filename}")
                
            except Exception as e:
                failed_files.append({
                    "filename": image_file.filename,
                    "error": str(e)
                })
        
        # Update dataset stats
        config.total_images = len(list(config.images_path.glob("*.jpg"))) + len(list(config.images_path.glob("*.png")))
        
        return {
            "uploaded": len(uploaded_files),
            "failed": len(failed_files),
            "uploaded_files": uploaded_files,
            "failed_files": failed_files,
            "total_images": config.total_images
        }
    
    def upload_annotations(self, dataset_id: str, annotation_files: List[UploadFile],
                          stage: DatasetStage = DatasetStage.AI_PREDICTIONS) -> Dict[str, Any]:
        """Upload annotations to specific stage of active learning pipeline"""
        
        if dataset_id not in self.datasets:
            raise ValueError(f"Dataset {dataset_id} not found")
        
        config = self.datasets[dataset_id]
        
        # Determine target directory based on stage
        if stage == DatasetStage.AI_PREDICTIONS:
            target_dir = config.predictions_path
        elif stage == DatasetStage.CORRECTED_LABELS:
            target_dir = config.corrections_path
        else:
            target_dir = config.annotations_path
        
        uploaded_annotations = []
        format_conversions = []
        
        for ann_file in annotation_files:
            try:
                # Save original file
                ann_path = target_dir / ann_file.filename
                with open(ann_path, 'wb') as f:
                    content = ann_file.file.read()
                    f.write(content)
                
                # Detect format
                detected_format = self.converter.detect_format(ann_path)
                
                # Convert to other formats if needed
                if detected_format != config.annotation_format:
                    converted_files = self._convert_annotation_format(
                        ann_path, detected_format, config.annotation_format, target_dir
                    )
                    format_conversions.extend(converted_files)
                
                uploaded_annotations.append({
                    "filename": ann_file.filename,
                    "format": detected_format.value,
                    "stage": stage.value,
                    "path": str(ann_path)
                })
                
            except Exception as e:
                logger.error(f"Failed to upload annotation {ann_file.filename}: {e}")
        
        # Update dataset stats
        if stage == DatasetStage.AI_PREDICTIONS:
            config.predictions_count = len(list(config.predictions_path.glob("*")))
        elif stage == DatasetStage.CORRECTED_LABELS:
            config.corrections_count = len(list(config.corrections_path.glob("*")))
        
        return {
            "uploaded": len(uploaded_annotations),
            "annotations": uploaded_annotations,
            "conversions": format_conversions,
            "stage": stage.value
        }
    
    def _convert_annotation_format(self, source_path: Path, source_format: AnnotationFormat,
                                  target_format: AnnotationFormat, output_dir: Path) -> List[Dict]:
        """Convert annotation between formats"""
        
        conversions = []
        
        try:
            if source_format == AnnotationFormat.YOLO_TXT and target_format == AnnotationFormat.COCO_JSON:
                output_path = output_dir / f"{source_path.stem}_converted.json"
                coco_data = self.converter.convert_yolo_to_coco(
                    source_path.parent, output_path, source_path.parent.parent / "images"
                )
                conversions.append({
                    "from": source_format.value,
                    "to": target_format.value,
                    "output": str(output_path)
                })
            
            elif source_format == AnnotationFormat.COCO_JSON and target_format == AnnotationFormat.YOLO_TXT:
                yolo_dir = output_dir / f"{source_path.stem}_yolo"
                yolo_dir.mkdir(exist_ok=True)
                success = self.converter.convert_coco_to_yolo(source_path, yolo_dir)
                if success:
                    conversions.append({
                        "from": source_format.value,
                        "to": target_format.value,
                        "output": str(yolo_dir)
                    })
            
            elif target_format == AnnotationFormat.CSV_TABULAR:
                output_path = output_dir / f"{source_path.stem}_converted.csv"
                success = self.converter.convert_to_csv(source_path, output_path)
                if success:
                    conversions.append({
                        "from": source_format.value,
                        "to": target_format.value,
                        "output": str(output_path)
                    })
            
        except Exception as e:
            logger.error(f"Conversion failed: {e}")
        
        return conversions
    
    def _validate_image(self, image_file: UploadFile) -> bool:
        """Validate uploaded image file"""
        try:
            # Check file extension
            allowed_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
            ext = Path(image_file.filename).suffix.lower()
            if ext not in allowed_extensions:
                return False
            
            # Try to load with PIL
            image_file.file.seek(0)
            img = Image.open(image_file.file)
            img.verify()  # Verify it's a valid image
            image_file.file.seek(0)  # Reset file pointer
            
            return True
            
        except Exception:
            return False
    
    def get_dataset_info(self, dataset_id: str) -> Dict[str, Any]:
        """Get comprehensive dataset information"""
        
        if dataset_id not in self.datasets:
            raise ValueError(f"Dataset {dataset_id} not found")
        
        config = self.datasets[dataset_id]
        
        # Count files in each stage
        images_count = len(list(config.images_path.glob("*")))
        predictions_count = len(list(config.predictions_path.glob("*")))
        corrections_count = len(list(config.corrections_path.glob("*")))
        
        # Calculate dataset quality
        quality_score = self._calculate_dataset_quality(config)
        
        return {
            "dataset_id": dataset_id,
            "name": config.name,
            "model_type": config.model_type.value,
            "annotation_format": config.annotation_format.value,
            "description": config.description,
            "created_at": config.created_at.isoformat(),
            "statistics": {
                "total_images": images_count,
                "predictions": predictions_count,
                "corrections": corrections_count,
                "dataset_quality": quality_score,
                "active_learning_cycles": config.retrain_cycles
            },
            "training_parameters": config.training_params,
            "paths": {
                "base": str(config.base_path),
                "images": str(config.images_path),
                "predictions": str(config.predictions_path),
                "corrections": str(config.corrections_path)
            },
            "ready_for_training": quality_score > 0.7 and images_count > 10
        }
    
    def _calculate_dataset_quality(self, config: DatasetConfiguration) -> float:
        """Calculate dataset quality score"""
        
        images_count = len(list(config.images_path.glob("*")))
        if images_count == 0:
            return 0.0
        
        predictions_count = len(list(config.predictions_path.glob("*")))
        corrections_count = len(list(config.corrections_path.glob("*")))
        
        # Quality factors
        size_score = min(1.0, images_count / 100.0)  # Target 100+ images
        annotation_score = min(1.0, predictions_count / images_count)
        correction_score = min(1.0, corrections_count / max(1, predictions_count))
        
        # Weighted quality
        quality = (size_score * 0.4 + annotation_score * 0.4 + correction_score * 0.2)
        
        return round(quality, 3)
    
    def list_datasets(self, model_type: Optional[ModelType] = None) -> List[Dict[str, Any]]:
        """List all datasets with optional filtering"""
        
        datasets = []
        
        for dataset_id, config in self.datasets.items():
            if model_type is None or config.model_type == model_type:
                info = self.get_dataset_info(dataset_id)
                datasets.append(info)
        
        return sorted(datasets, key=lambda x: x["created_at"], reverse=True)
    
    def prepare_training_data(self, dataset_id: str) -> Dict[str, Any]:
        """Prepare dataset for training with train/val split"""
        
        if dataset_id not in self.datasets:
            raise ValueError(f"Dataset {dataset_id} not found")
        
        config = self.datasets[dataset_id]
        training_dir = config.base_path / "training_ready"
        
        # Create train/val directories
        train_dir = training_dir / "train"
        val_dir = training_dir / "val"
        
        for split_dir in [train_dir, val_dir]:
            (split_dir / "images").mkdir(parents=True, exist_ok=True)
            (split_dir / "labels").mkdir(parents=True, exist_ok=True)
        
        # Get image and annotation files
        image_files = list(config.images_path.glob("*"))
        
        # Use corrected labels if available, otherwise predictions
        if config.corrections_count > 0:
            label_source = config.corrections_path
            label_type = "corrected"
        else:
            label_source = config.predictions_path
            label_type = "predictions"
        
        # 80/20 split
        split_idx = int(0.8 * len(image_files))
        train_images = image_files[:split_idx]
        val_images = image_files[split_idx:]
        
        # Copy files to training structure
        train_count = self._copy_training_files(train_images, label_source, train_dir)
        val_count = self._copy_training_files(val_images, label_source, val_dir)
        
        # Create dataset.yaml for YOLO training
        dataset_yaml = training_dir / "dataset.yaml"
        with open(dataset_yaml, 'w') as f:
            f.write(f"""
path: {training_dir}
train: train/images
val: val/images
nc: 5
names: ['card', 'border', 'corner', 'edge', 'damage']

# Revolutionary dataset configuration
model_type: {config.model_type.value}
annotation_format: {config.annotation_format.value}
label_source: {label_type}
training_params:
{json.dumps(config.training_params, indent=2)}
""")
        
        return {
            "dataset_id": dataset_id,
            "training_ready": True,
            "train_samples": train_count,
            "val_samples": val_count,
            "total_samples": train_count + val_count,
            "label_source": label_type,
            "config_file": str(dataset_yaml),
            "training_params": config.training_params
        }
    
    def _copy_training_files(self, image_files: List[Path], label_source: Path, 
                           target_dir: Path) -> int:
        """Copy image and label files to training directory"""
        
        copied_count = 0
        
        for img_file in image_files:
            try:
                # Copy image
                target_img = target_dir / "images" / img_file.name
                shutil.copy2(img_file, target_img)
                
                # Copy corresponding label
                label_files = list(label_source.glob(f"{img_file.stem}.*"))
                if label_files:
                    label_file = label_files[0]
                    target_label = target_dir / "labels" / f"{img_file.stem}.txt"
                    shutil.copy2(label_file, target_label)
                    copied_count += 1
                
            except Exception as e:
                logger.error(f"Failed to copy training files for {img_file.name}: {e}")
        
        return copied_count

class RevolutionaryDatasetAPI:
    """FastAPI interface for revolutionary dataset management"""
    
    def __init__(self):
        self.app = FastAPI(title="Revolutionary Dataset Management Studio")
        self.setup_cors()
        self.manager = RevolutionaryDatasetManager()
        self.setup_routes()
        
    def setup_cors(self):
        self.app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
    
    def setup_routes(self):
        
        @self.app.get("/")
        async def dashboard():
            return HTMLResponse(self.get_dashboard_html())
        
        @self.app.post("/api/datasets/create")
        async def create_dataset(
            name: str = Form(...),
            model_type: str = Form(...),
            annotation_format: str = Form(...),
            description: str = Form(""),
            training_params: str = Form("{}")
        ):
            """Create new revolutionary dataset"""
            try:
                model_type_enum = ModelType(model_type)
                format_enum = AnnotationFormat(annotation_format)
                params = json.loads(training_params) if training_params else None
                
                dataset_id = self.manager.create_dataset(
                    name, model_type_enum, format_enum, description, params
                )
                
                return {
                    "success": True,
                    "dataset_id": dataset_id,
                    "message": f"Revolutionary dataset '{name}' created",
                    "model_type": model_type,
                    "paths_created": True
                }
                
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))
        
        @self.app.post("/api/datasets/{dataset_id}/upload-images")
        async def upload_images(dataset_id: str, files: List[UploadFile] = File(...)):
            """Upload images to dataset"""
            try:
                result = self.manager.upload_images(dataset_id, files)
                return {
                    "success": True,
                    "dataset_id": dataset_id,
                    **result
                }
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))
        
        @self.app.post("/api/datasets/{dataset_id}/upload-annotations")
        async def upload_annotations(
            dataset_id: str,
            stage: str = Form(...),
            files: List[UploadFile] = File(...)
        ):
            """Upload annotations to specific pipeline stage"""
            try:
                stage_enum = DatasetStage(stage)
                result = self.manager.upload_annotations(dataset_id, files, stage_enum)
                return {
                    "success": True,
                    "dataset_id": dataset_id,
                    **result
                }
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))
        
        @self.app.get("/api/datasets")
        async def list_datasets(model_type: Optional[str] = None):
            """List all datasets with optional filtering"""
            try:
                model_type_enum = ModelType(model_type) if model_type else None
                datasets = self.manager.list_datasets(model_type_enum)
                return {
                    "success": True,
                    "datasets": datasets,
                    "total": len(datasets)
                }
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))
        
        @self.app.get("/api/datasets/{dataset_id}")
        async def get_dataset_info(dataset_id: str):
            """Get comprehensive dataset information"""
            try:
                info = self.manager.get_dataset_info(dataset_id)
                return {
                    "success": True,
                    **info
                }
            except Exception as e:
                raise HTTPException(status_code=404, detail=str(e))
        
        @self.app.post("/api/datasets/{dataset_id}/prepare-training")
        async def prepare_training_data(dataset_id: str):
            """Prepare dataset for training"""
            try:
                result = self.manager.prepare_training_data(dataset_id)
                return {
                    "success": True,
                    **result
                }
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))
    
    def get_dashboard_html(self) -> str:
        """Revolutionary dataset management dashboard"""
        return '''
        <!DOCTYPE html>
        <html>
        <head>
            <title>🚀 Revolutionary Dataset Studio</title>
            <style>
                * { margin: 0; padding: 0; box-sizing: border-box; }
                body {
                    font-family: 'Segoe UI', system-ui, sans-serif;
                    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
                    min-height: 100vh; color: #333;
                }
                .container { max-width: 1800px; margin: 0 auto; padding: 20px; }
                .header {
                    background: rgba(255,255,255,0.95); border-radius: 20px;
                    padding: 40px; text-align: center; margin-bottom: 30px;
                    box-shadow: 0 20px 40px rgba(0,0,0,0.1);
                }
                .header h1 {
                    font-size: 3.5em; font-weight: 300; margin-bottom: 10px;
                    background: linear-gradient(45deg, #667eea, #764ba2);
                    -webkit-background-clip: text; -webkit-text-fill-color: transparent;
                }
                .modules-grid {
                    display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
                    gap: 20px; margin: 30px 0;
                }
                .module-card {
                    background: rgba(255,255,255,0.95); padding: 25px; border-radius: 15px;
                    box-shadow: 0 10px 25px rgba(0,0,0,0.1); transition: all 0.3s;
                }
                .module-card:hover { transform: translateY(-5px); }
                .module-card h3 {
                    color: #667eea; margin-bottom: 15px; font-size: 1.3em;
                }
                .pipeline-visual {
                    background: rgba(255,255,255,0.95); border-radius: 15px;
                    padding: 30px; margin: 20px 0;
                }
                .pipeline-steps {
                    display: flex; justify-content: space-between; align-items: center;
                    margin: 20px 0;
                }
                .pipeline-step {
                    background: #667eea; color: white; padding: 15px 20px;
                    border-radius: 10px; font-weight: bold; flex: 1;
                    text-align: center; margin: 0 5px;
                }
                .btn {
                    background: #4ecdc4; color: white; padding: 15px 30px;
                    border: none; border-radius: 8px; cursor: pointer;
                    font-size: 16px; margin: 10px 5px; transition: all 0.3s;
                }
                .btn:hover { background: #45b7b8; transform: translateY(-2px); }
                .btn-create { background: #667eea; }
                .btn-create:hover { background: #5a67d8; }
            </style>
        </head>
        <body>
            <div class="container">
                <div class="header">
                    <h1>🚀 Revolutionary Dataset Studio</h1>
                    <p>Comprehensive ML Training Dataset Management</p>
                    <p style="font-size: 0.9em; color: #666; margin-top: 10px;">
                        Edge • Corner • Damage • Surface • Photometric Fusion
                    </p>
                </div>

                <div class="pipeline-visual">
                    <h2>🔄 Active Learning Pipeline</h2>
                    <div class="pipeline-steps">
                        <div class="pipeline-step">📁 Raw Images</div>
                        <div class="pipeline-step">🤖 AI Predictions</div>
                        <div class="pipeline-step">✏️ Human Corrections</div>
                        <div class="pipeline-step">🚀 Retrain Models</div>
                    </div>
                    <p style="text-align: center; margin-top: 15px; color: #666;">
                        Upload → AI predicts → You correct → Model improves
                    </p>
                </div>

                <div class="modules-grid">
                    <div class="module-card">
                        <h3>🎯 Edge Detection</h3>
                        <p><strong>Purpose:</strong> Train models to detect card edges with pixel precision</p>
                        <p><strong>Architecture:</strong> Detectron2 + Custom edge refinement</p>
                        <p><strong>Applications:</strong> Centering analysis, border quality</p>
                        <button class="btn btn-create" onclick="createDataset('edge_detection')">Create Edge Dataset</button>
                    </div>

                    <div class="module-card">
                        <h3>📐 Corner Detection</h3>
                        <p><strong>Purpose:</strong> Precise corner location and quality assessment</p>
                        <p><strong>Architecture:</strong> Mask R-CNN + Corner regression</p>
                        <p><strong>Applications:</strong> Corner grading, damage detection</p>
                        <button class="btn btn-create" onclick="createDataset('corner_detection')">Create Corner Dataset</button>
                    </div>

                    <div class="module-card">
                        <h3>⚡ Edge Damage</h3>
                        <p><strong>Purpose:</strong> Detect edge wear, cuts, and imperfections</p>
                        <p><strong>Architecture:</strong> Specialized damage classification</p>
                        <p><strong>Applications:</strong> Edge quality grading</p>
                        <button class="btn btn-create" onclick="createDataset('edge_damage')">Create Edge Damage Dataset</button>
                    </div>

                    <div class="module-card">
                        <h3>📍 Corner Damage</h3>
                        <p><strong>Purpose:</strong> Corner wear, dings, and rounding detection</p>
                        <p><strong>Architecture:</strong> Multi-scale damage analysis</p>
                        <p><strong>Applications:</strong> Corner condition assessment</p>
                        <button class="btn btn-create" onclick="createDataset('corner_damage')">Create Corner Damage Dataset</button>
                    </div>

                    <div class="module-card">
                        <h3>🌊 Surface Damage</h3>
                        <p><strong>Purpose:</strong> Scratches, creases, and surface defects</p>
                        <p><strong>Architecture:</strong> High-resolution surface analysis</p>
                        <p><strong>Applications:</strong> Surface quality grading</p>
                        <button class="btn btn-create" onclick="createDataset('surface_damage')">Create Surface Dataset</button>
                    </div>

                    <div class="module-card">
                        <h3>📏 Centering Analysis</h3>
                        <p><strong>Purpose:</strong> Precise border measurement and centering</p>
                        <p><strong>Architecture:</strong> Geometric analysis + ML refinement</p>
                        <p><strong>Applications:</strong> Centering grade calculation</p>
                        <button class="btn btn-create" onclick="createDataset('centering_analysis')">Create Centering Dataset</button>
                    </div>

                    <div class="module-card" style="border: 3px solid #FFD700; background: linear-gradient(135deg, #fff 0%, #fffbf0 100%);">
                        <h3>🔬 Photometric Fusion</h3>
                        <p><strong>Revolutionary:</strong> Combine AI + photometric stereo data</p>
                        <p><strong>Architecture:</strong> Custom multi-modal fusion networks</p>
                        <p><strong>Applications:</strong> Patent-worthy analysis techniques</p>
                        <button class="btn" style="background: #FFD700; color: #333;" onclick="createDataset('photometric_fusion')">Create Fusion Dataset</button>
                    </div>

                    <div class="module-card">
                        <h3>🌐 Multi-Modal</h3>
                        <p><strong>Purpose:</strong> Combine multiple detection types</p>
                        <p><strong>Architecture:</strong> Ensemble and fusion models</p>
                        <p><strong>Applications:</strong> Comprehensive card analysis</p>
                        <button class="btn btn-create" onclick="createDataset('multi_modal')">Create Multi-Modal Dataset</button>
                    </div>
                </div>

                <div style="text-align: center; margin: 40px 0;">
                    <button class="btn" onclick="viewAllDatasets()" style="font-size: 18px; padding: 20px 40px;">
                        📋 View All Datasets
                    </button>
                    <button class="btn" onclick="showTrainingQueue()" style="font-size: 18px; padding: 20px 40px;">
                        🚀 Training Queue
                    </button>
                </div>
            </div>

            <script>
                function createDataset(modelType) {
                    const name = prompt(`Enter name for ${modelType.replace('_', ' ')} dataset:`);
                    if (!name) return;

                    const formData = new FormData();
                    formData.append('name', name);
                    formData.append('model_type', modelType);
                    formData.append('annotation_format', 'coco_json');
                    formData.append('description', `${modelType.replace('_', ' ')} dataset for revolutionary training`);

                    fetch('/api/datasets/create', {
                        method: 'POST',
                        body: formData
                    })
                    .then(response => response.json())
                    .then(data => {
                        if (data.success) {
                            alert(`✅ Dataset created successfully!\\n\\nDataset ID: ${data.dataset_id}\\nType: ${modelType}`);
                            // Could redirect to dataset management page
                        } else {
                            alert(`❌ Error: ${data.detail}`);
                        }
                    })
                    .catch(error => {
                        alert(`❌ Error: ${error.message}`);
                    });
                }

                function viewAllDatasets() {
                    fetch('/api/datasets')
                    .then(response => response.json())
                    .then(data => {
                        if (data.success) {
                            const datasets = data.datasets;
                            let message = `📋 Active Datasets (${datasets.length}):\\n\\n`;
                            
                            datasets.forEach(dataset => {
                                message += `• ${dataset.name} (${dataset.model_type})\\n`;
                                message += `  Images: ${dataset.statistics.total_images}\\n`;
                                message += `  Quality: ${(dataset.statistics.dataset_quality * 100).toFixed(1)}%\\n\\n`;
                            });
                            
                            alert(message);
                        }
                    })
                    .catch(error => alert(`Error: ${error.message}`));
                }

                function showTrainingQueue() {
                    alert('🚀 Training Queue\\n\\nThis will show active training jobs, queued datasets, and training progress.\\n\\nComing soon!');
                }
            </script>
        </body>
        </html>
        '''

# Initialize the revolutionary dataset API
revolutionary_dataset_api = RevolutionaryDatasetAPI()

async def main():
    """Launch the revolutionary dataset studio"""
    import uvicorn
    
    config = uvicorn.Config(
        revolutionary_dataset_api.app,
        host="0.0.0.0",
        port=8007,
        log_level="info"
    )
    server = uvicorn.Server(config)
    
    print("🚀 Revolutionary Dataset Management Studio")
    print("=" * 60)
    print("📁 Modular Dataset Organization: Edge • Corner • Damage • Surface")
    print("🔄 Active Learning Pipeline: Raw → Predictions → Corrections → Retrain")
    print("🔧 Multi-Format Support: COCO • YOLO • CSV with intelligent conversion")
    print("🔬 Photometric Fusion: Revolutionary AI + Photometric integration")
    print("🌐 Web Interface: http://localhost:8007")
    print("=" * 60)
    print("Built for revolutionary ML training! 🔥")
    
    await server.serve()

if __name__ == "__main__":
    asyncio.run(main())
